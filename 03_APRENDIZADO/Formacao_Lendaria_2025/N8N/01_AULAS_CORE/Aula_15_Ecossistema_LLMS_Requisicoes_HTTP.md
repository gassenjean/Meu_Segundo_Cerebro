# AULA 15 - ECOSSISTEMA LLMS E REQUISI√á√ïES HTTP

---
**M√ìDULO**: N8N Mastery  
**SEQU√äNCIA**: 15/11  
**DURA√á√ÉO**: 45min  
**PREREQUISITOS**: Aula 14 - HTTP Request  
**CRIADO**: 28/07/2025 por N√©voa
---

## ‚ö° RESUMO EXECUTIVO
- **Dominar√° todos os LLMs**: ChatGPT, Claude, Gemini, Groq, Perplexity e outros
- **Mestre das requisi√ß√µes HTTP**: estrutura, headers, body para cada modelo
- **Integra√ß√£o N8N universal**: conectar qualquer LLM em automa√ß√µes

## üéØ CONCEITOS-CHAVE

### **Anatomia Requisi√ß√£o HTTP para LLMs**
- **URL**: Endpoint espec√≠fico de cada provedor
- **Headers**: Autentica√ß√£o (Bearer, API-Key) + Content-Type
- **Body**: Payload JSON com modelo, mensagens e par√¢metros

### **Diferen√ßas Entre Provedores**
- **OpenAI**: `/v1/chat/completions` + Bearer token
- **Claude**: `/v1/messages` + x-api-key header  
- **Gemini**: `/v1beta/models/{model}:generateContent` + key param
- **Groq**: `/openai/v1/chat/completions` + Bearer token
- **Perplexity**: `/chat/completions` + Bearer token

### **Estruturas de Mensagem**
- **Padr√£o**: `{"role": "user", "content": "texto"}`
- **Claude**: `{"role": "user", "content": [{"type": "text", "text": "..."}]}`
- **Sistema**: role "system" para contexto/personalidade

## üíª IMPLEMENTA√á√ÉO PR√ÅTICA

### **Template B√°sico N8N - HTTP Request LLM**
```json
{
  "method": "POST",
  "url": "https://api.openai.com/v1/chat/completions",
  "headers": {
    "Authorization": "Bearer {{$env.OPENAI_API_KEY}}",
    "Content-Type": "application/json"
  },
  "body": {
    "model": "gpt-4",
    "messages": [
      {"role": "system", "content": "Voc√™ √© um assistente especializado"},
      {"role": "user", "content": "{{$node.Webhook.json.text}}"}
    ],
    "max_tokens": 1000,
    "temperature": 0.7
  }
}
```

### **Workflow Multi-LLM Inteligente**
1. **Node Webhook**: Recebe input do usu√°rio
2. **Node Switch**: Escolhe LLM baseado em crit√©rio
3. **Nodes HTTP Request**: Um para cada LLM
4. **Node Merge**: Combina respostas
5. **Node Response**: Retorna resultado final

### **Gest√£o de API Keys**
- Usar vari√°veis de ambiente: `{{$env.OPENAI_API_KEY}}`
- Configurar em Settings > Environment variables
- Nunca hardcoded no workflow

## üõ†Ô∏è CASOS DE USO - MEUS PROJETOS

### **N√âVOA IA**:
- **Fallback inteligente**: OpenAI principal ‚Üí Claude backup ‚Üí Groq emergencial
- **Especializa√ß√£o por modelo**: GPT-4 (texto), Claude (an√°lise), Groq (velocidade)
- **Cost optimization**: Groq para respostas simples, GPT-4 para complexas

### **EVANGELISMO DIGITAL**:
- **Gera√ß√£o conte√∫do**: Claude para reflex√µes profundas
- **Imagens**: DALL-E para ilustra√ß√µes b√≠blicas
- **Velocidade**: Groq para respostas r√°pidas em lives

### **GABRIELE CONFEC√á√ïES/KABAK**:
- **Atendimento**: Groq para respostas instant√¢neas
- **Copywriting**: GPT-4 para descri√ß√µes de produtos
- **An√°lise feedback**: Claude para insights de clientes

## üîó CONEX√ïES

### **BUILDS SOBRE**:
- Aula 14: HTTP Request fundamentals
- Aula 10: IA Generativa b√°sica
- Aula 08: Integra√ß√£o WhatsApp

### **PREPARA PARA**:
- Pr√≥xima: Orquestra√ß√£o avan√ßada de m√∫ltiplos LLMs
- Pipeline de IA distribu√≠da
- Otimiza√ß√£o de custos automatizada

## ‚úÖ CHECKLIST AULA 15

### **CONCEITUAL**:
- [ ] Entendo diferen√ßas entre provedores LLM
- [ ] Sei estruturar requisi√ß√µes HTTP para cada um
- [ ] Compreendo vantagens/desvantagens de cada modelo

### **PR√ÅTICO**:
- [ ] Configurei pelo menos 3 LLMs diferentes no N8N
- [ ] Criei workflow com fallback autom√°tico
- [ ] Testei gera√ß√£o de texto e imagem

### **APLICA√á√ÉO**:
- [ ] Implementei multi-LLM em projeto real
- [ ] Configurei otimiza√ß√£o de custos
- [ ] Documentei performance de cada modelo

---
**STATUS**: ‚úÖ Ecossistema LLM dominado - requisi√ß√µes HTTP universais
**PR√ìXIMO**: Orquestra√ß√£o avan√ßada e otimiza√ß√£o de custos