---
criado: 2024-10-01T11:16:53-03:00
atualizado: 2025-07-09T20:27:08-03:00
---

#consumir

# **Sugest√£o da cadeia de pensamento**

Quando mesmo o few-shot n√£o √© suficiente?

√â a√≠ que entra o Prompting da Cadeia de Pensamento (CoT)!

Nesta aula, vamos aprender:

- O que √© CoT Prompting e como ele difere do prompting tradicional
- Como aplicar CoT Prompting para resolver problemas de racioc√≠nio complexo
- T√©cnicas avan√ßadas como Zero-Shot CoT e Auto-CoT
- Dicas pr√°ticas, exemplos de uso e aplica√ß√µes no mundo dos neg√≥cios
- Uma pr√©via da pr√≥xima t√©cnica que vamos estudar: Self-Consistency

Ent√£o vamos l√°, √© hora de levar seus prompts para o pr√≥ximo n√≠vel! üöÄ

## O que √© Chain-of-Thought Prompting?

Chain-of-Thought (CoT) Prompting √© uma t√©cnica avan√ßada que incentiva os Grandes Modelos de Linguagem (LLMs) a explicarem seu racioc√≠nio passo a passo antes de chegar √† resposta final.

A ideia central do CoT √© que, ao mostrar exemplos (few-shot) onde o processo de racioc√≠nio √© explicado, o modelo aprende a mostrar seu pr√≥prio racioc√≠nio ao responder novos prompts. E essa explica√ß√£o geralmente leva a resultados mais precisos e interpret√°veis.

## Aplicando CoT Prompting na Pr√°tica

![](https://api-club-file.cb.hotmart.com/public/v5/files/f7e95dd0-d7dc-44ba-a126-d31bf22cfb3e)

Sa√≠da:

![](https://api-club-file.cb.hotmart.com/public/v5/files/1fb98194-2e0a-4a3f-9707-d46e7b9dc836)

Explicando um PDF:

![](https://api-club-file.cb.hotmart.com/public/v5/files/db7d4709-52e0-4f76-93a2-9af6a4cff310)

Sa√≠da:

### ![](https://api-club-file.cb.hotmart.com/public/v5/files/2d5f3ced-00c8-428b-bf8f-c328af2a61d8)

### Aplica√ß√µes Pr√°ticas de CoT Prompting

O CoT Prompting pode ser uma ferramenta poderosa em v√°rias √°reas de neg√≥cios:

- **Marketing**: Gere explica√ß√µes passo a passo de como uma campanha de marketing levar√° aos resultados desejados, tornando a estrat√©gia mais clara e convincente.
- **Gest√£o de Projetos**: Decomponha tarefas complexas em etapas menores e mais gerenci√°veis, explicando a l√≥gica por tr√°s de cada passo. Isso ajuda a equipe a entender melhor seus pap√©is e responsabilidades.
- **An√°lise de Dados**: Interprete resultados de an√°lises complexas, detalhando o racioc√≠nio por tr√°s de cada insight. Isso torna as descobertas mais acess√≠veis e acion√°veis para tomadores de decis√£o.
- **Cria√ß√£o de Conte√∫do**: Gere artigos, posts e ebooks com uma estrutura l√≥gica clara, fornecendo exemplos passo a passo de conceitos chave. Isso torna o conte√∫do mais envolvente e educativo.

CoT √© especialmente valioso para problemas que requerem m√∫ltiplas etapas de racioc√≠nio ou t√™m v√°rias considera√ß√µes a serem analisadas. Quanto mais complexa a tarefa, maior o benef√≠cio potencial do CoT.

## T√©cnicas Avan√ßadas de CoT

### CoT de tiro zero

E se voc√™ n√£o tiver bons exemplos para dar? Entra em cena o Zero-Shot CoT!

_R√°pido:_

I went to the market and bought 10 apples. I gave 2 apples to the neighbor and 2 to the repairman. I then went and bought 5 more apples and ate 1. How many apples did I remain with?

_Output:_

11 apples

A resposta est√° incorreta! Agora vamos tentar com o prompt CoT.

_Prompt:_

I went to the market and bought 10 apples. I gave 2 apples to the neighbor and 2 to the repairman. I then went and bought 5 more apples and ate 1. How many apples did I remain with?Let's think step by step.

_Output:_

First, you started with 10 apples.You gave away 2 apples to the neighbor and 2 to the repairman, so you had 6 apples left.Then you bought 5 more apples, so now you had 11 apples.Finally, you ate 1 apple, so you would remain with 10 apples.

A ideia √© simplesmente adicionar a frase "Vamos pensar passo a passo" ao prompt original.

R√°pido:

Fui ao mercado e comprei 10 ma√ß√£s. Dei 2 ma√ß√£s para o vizinho e 2 para o t√©cnico. Depois comprei mais 5 ma√ß√£s e comi 1. Com quantas ma√ß√£s fiquei?

Vamos pensar passo a passo:

Resposta:

Primeiro, voc√™ come√ßou com 10 ma√ß√£s.

Voc√™ deu 2 ma√ß√£s para o vizinho e 2 para o t√©cnico, ficando com 6 ma√ß√£s.

Ent√£o voc√™ comprou mais 5 ma√ß√£s, ficando com 11 ma√ß√£s.

Por fim, voc√™ comeu 1 ma√ß√£, sobrando 10 ma√ß√£s.

Portanto, voc√™ ficou com 10 ma√ß√£s.

![](https://api-club-file.cb.hotmart.com/public/v5/files/a6454710-576d-4e49-9bda-ef92985bb567)

Incr√≠vel como esse prompt simples j√° faz o modelo explicar seu racioc√≠nio! Isso √© especialmente √∫til quando voc√™ n√£o tem muitos exemplos para dar.

## Resumo

- A Solicita√ß√£o da Cadeia de Pensamento permite que os LLMs expliquem seu racioc√≠nio passo a passo
- CoT leva a respostas mais precisas e interpret√°veis em tarefas complexas
- Zero-Shot CoT e Auto-CoT facilitam a aplica√ß√£o de CoT sem muitos exemplos
- CoT tem aplica√ß√µes pr√°ticas em marketing, gest√£o de projetos, an√°lise de dados e cria√ß√£o de conte√∫do
- CoT pode ser combinado com Self-Consistency (pr√©via da pr√≥xima aula) para melhorar ainda mais a precis√£o

Experimente aplicar CoT aos seus prompts e veja a m√°gica acontecer! Na pr√≥xima aula vamos elevar ainda mais com Self-Consistency.

At√© l√°, divirta-se explorando o poder do racioc√≠nio passo-a-passo em seus projetos! E compartilhe seus prompts e resultados no f√≥rum para inspirar os colegas.

## Refer√™ncias

[https://arxiv.org/pdf/2201.11903](https://arxiv.org/pdf/2201.11903)

[https://arxiv.org/pdf/2309.15402](https://arxiv.org/pdf/2309.15402)

[https://arxiv.org/pdf/2203.11171](https://arxiv.org/pdf/2203.11171)

1. Wei, J., Wang, X., Schuurmans, D., Bosma, M., Chi, E., Le, Q., & Zhou, D. (2022). A cadeia de est√≠mulo da cadeia de pensamento provoca o racioc√≠nio em grandes modelos de linguagem. pr√©-impress√£o arXiv arXiv:2201.11903.
2. Kojima, T., Gu, S. S., Reid, M., Matsuo, Y., & Iwasawa, Y. (2022). Grandes modelos de linguagem s√£o raciocinadores zero-shot. pr√©-impress√£o arXiv arXiv:2205.11916.
3. Wang, X., Wei, J., Schuurmans, D., Le, Q., Chi, E., & Zhou, D. (2022). A autoconsist√™ncia melhora o racioc√≠nio da cadeia de pensamento em modelos de linguagem. pr√©-impress√£o arXiv arXiv:2203.11171.
4. Zhang, J., Yao, N., Xie, S., Chen, H., Yin, R., Jia, R., ... & Wang, X. (2023). Solicita√ß√£o autom√°tica de cadeia de pensamento em grandes modelos de linguagem. pr√©-impress√£o arXiv arXiv:2210.03493.

## Recursos Adicionais

[https://www.mercity.ai/blog-post/guide-to-chain-of-thought-prompting](https://www.mercity.ai/blog-post/guide-to-chain-of-thought-prompting)

# ia

O texto apresenta uma explica√ß√£o detalhada sobre o Chain-of-Thought (CoT) Prompting, uma t√©cnica avan√ßada para melhorar a precis√£o e interpretabilidade dos modelos de linguagem grandes (LLMs). Aqui est√° um resumo dos principais pontos:

**O que √© CoT Prompting?**

CoT Prompting √© uma t√©cnica que incentiva os LLMs a explicar seu racioc√≠nio passo a passo antes de chegar √† resposta final. Isso √© feito adicionando uma frase ao prompt original, como "Vamos pensar passo a passo".

**Benef√≠cios do CoT Prompting**

- Leva a respostas mais precisas e interpret√°veis em tarefas complexas
- Pode ser especialmente √∫til para problemas que requerem m√∫ltiplas etapas de racioc√≠nio ou t√™m v√°rias considera√ß√µes a serem analisadas

**T√©cnicas Avan√ßadas de CoT**

- Zero-Shot CoT: permite que os LLMs expliquem seu racioc√≠nio sem exemplos pr√©vios
- Auto-CoT: facilita a aplica√ß√£o de CoT sem muitos exemplos

**Aplica√ß√µes Pr√°ticas de CoT**

- Marketing: gera√ß√£o de explica√ß√µes passo a passo de estrat√©gias de marketing
- Gest√£o de Projetos: decomposi√ß√£o de tarefas complexas em etapas menores e mais gerenci√°veis
- An√°lise de Dados: interpreta√ß√£o de resultados de an√°lises complexas
- Cria√ß√£o de Conte√∫do: gera√ß√£o de artigos, posts e ebooks com uma estrutura l√≥gica clara

**Refer√™ncias**

O texto inclui refer√™ncias a artigos acad√™micos que discutem a t√©cnica de CoT Prompting e suas aplica√ß√µes.

**Recursos Adicionais**

O texto inclui um link para um guia adicional sobre CoT Prompting.

Em resumo, o CoT Prompting √© uma t√©cnica poderosa para melhorar a precis√£o e interpretabilidade dos LLMs, com aplica√ß√µes pr√°ticas em v√°rias √°reas. A t√©cnica pode ser especialmente √∫til para problemas complexos que requerem m√∫ltiplas etapas de racioc√≠nio.
